When I was reflecting on the work I did on Cornell Data Science this past year, I thought it might be interesting to look back even further and write a post about the first project I did for CDS. I feel like doing a post-mortem (or to put it less morbidly, debriefing) for the project could yield some interesting lessons both on the technical side and on the teamwork/organization side. 

For some background, this project was done during the first semester that my subteam on CDS existed. With my only machine learning background being from a single upper-div course, I wouldn't have been a good fit for CDS normally; however, this subteam had a heavier emphasis on interpretability (of both methods and results) and I was brought onboard because of my experience with data visualization. Due to the newness of the subteam, I ended up being one of the older and more experienced recruits, despite having only taken a single upper-div machine learning course.

The project was called "Social Tribes", and as expected of a proposal made by a freshman, its goal was far too broad and ambitious: "to detect and visualize echo chambers in social media". Needless to say, the scope was soon reduced to "clustering political journalists on Twitter". The team was myself, three freshmen, and one senior. 

We ended up scraping lists of Twitter followers from some 400 political journalists and creating a pairwise similarity metric based on number of overlapping followers which we hoped would represent the overlap in their audiences. Then, we applied some unsupervised clustering algorithms to the data and created some visualizations based on the projections. The cluster quality was poor and the results were mostly inconclusive, although the clusters we did find seemed to be split more along the lines of famous commentators vs lesser known journalists. I got to experiment with several different interactive visualization techniques, including a [force-directed graph]() showing similar pairs of users, and several [dendrograms]() plus a dynamic [bubble chart]() showing the hierarcy and process of agglomerative clustering.

The biggest technical mistakes we made were probably in feature extraction. Since some accounts had millions of followers and some had hundreds, we were only able to extract a small percentage of the followers of larger accounts but still retrieved the entire lists of smaller accounts (due to Twitter rate limits). This means that small differences in which followers were selected from large accounts may have a major impact on the similarity metric, which raises the possibility that the clustering we saw was entirely artificially created by bad feature extraction. Due to lack of statistics background among the members of the team, there was also some resistance against various statistical tests and cluster quality evaluations that could have given us more confidence in our results.

Looking back at our combined technical background, our odds of succeeding were not good; most of the freshmen had no experience with ML, and the senior contributed nothing. For my part, I tried my best to read textbooks and literature for modeling and visualization techniques we could use for the project, but implementing meaningful things was challenging because of our combined inexperience with Python ML frameworks. Even contributing to the same codebase was difficult, because most of the members knew neither Python nor Javascript. Despite making a conscious effort to make my code clean, readable, and commented, no other members made major contributions to the visualizations I wrote. I'm not too surprised though, since the visualizations were written in D3.js (which, in my opinion, is difficult to pick up without significant training). 

From the start, this project suffered from a lack of leadership. There were three potential managers for this project: the senior (because he was the oldest), myself (because I had the most experience), and the freshman who created the project proposal. It was unreasonable to expect a freshman to effectively lead a team, but I was also reluctant to take charge because I didn't want to step on people's toes and be accused of hijacking the project. In the end, no one filled that role, and I believe that this negatively impacted the team's productivity and sense of direction. I sometimes regret not stepping in and taking charge of the project - as a sophomore I wasn't particularly confident in my ability to delegate tasks, but it probably would have been better than nothing. A rule of thumb that I concluded from this and other experiences is that teams of >4 people have an hard time making steady progress without someone managing and delegating tasks for the project. There are exceptions of course, but having an effective project manager will never hurt.

I think this project is pretty representative of the growing pains of creating a new team. It's always difficult to build up a knowledge base from scratch, and recruitment needs to be balanced between recruiting older, more experienced people who can contribute more v.s. recruiting younger, less experienced people who can continue the team in the future. I believe that effective onboarding and efficient project management are two key factors that can speed up this process, allowing a team to establish and distinguish itself much faster. 

Overall, although I felt like the project was unsuccessful in achieving its technical goals, I still learned a lot from the experience and the team was able to "get their feet wet" with this project. My experience with this motivated me to do two things. The first was creating a new onboarding curriculum for new members, complete with lecture slides and homeworks. After further refinements by other members, I'm pretty happy with the effectiveness of our onboarding process. The second action that I took was being more active in managing the project I was involved with the following semester. While that project was more productive and successful, it also showed that I needed to get better at delegating tasks to others - but that story is best left for another post.
